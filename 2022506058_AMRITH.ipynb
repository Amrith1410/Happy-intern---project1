{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN3sEiHjrOQE2Gq7ssEKOAU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# RECOMMENDATION SYSTEM 1"],"metadata":{"id":"XBjVF4MvDInA"}},{"cell_type":"markdown","source":["**MODEL 1 -- COLLABORATIVE MODEL**"],"metadata":{"id":"gv6Uq5v4sSR5"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"4EQ4zXecFDAi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720101955649,"user_tz":-330,"elapsed":216348,"user":{"displayName":"Amrith eshwar","userId":"12227259083114899190"}},"outputId":"ac4a1583-215e-4667-958f-583e8d95849f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n","WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","25/25 [==============================] - 18s 667ms/step - factorized_top_k/top_1_categorical_accuracy: 7.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0015 - factorized_top_k/top_10_categorical_accuracy: 0.0047 - factorized_top_k/top_50_categorical_accuracy: 0.0431 - factorized_top_k/top_100_categorical_accuracy: 0.0977 - loss: 33096.4720 - regularization_loss: 0.0000e+00 - total_loss: 33096.4720\n","Epoch 2/3\n","25/25 [==============================] - 15s 604ms/step - factorized_top_k/top_1_categorical_accuracy: 1.6000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0138 - factorized_top_k/top_50_categorical_accuracy: 0.1046 - factorized_top_k/top_100_categorical_accuracy: 0.2094 - loss: 31007.5086 - regularization_loss: 0.0000e+00 - total_loss: 31007.5086\n","Epoch 3/3\n","25/25 [==============================] - 15s 603ms/step - factorized_top_k/top_1_categorical_accuracy: 4.2000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0079 - factorized_top_k/top_10_categorical_accuracy: 0.0216 - factorized_top_k/top_50_categorical_accuracy: 0.1426 - factorized_top_k/top_100_categorical_accuracy: 0.2671 - loss: 30417.1460 - regularization_loss: 0.0000e+00 - total_loss: 30417.1460\n","Top 3 recommendations for user 42: [b'Rent-a-Kid (1995)'\n"," b'Land Before Time III: The Time of the Great Giving (1995) (V)'\n"," b'Aristocats, The (1970)']\n"]}],"source":["!pip install -q tensorflow-recommenders\n","!pip install -q --upgrade tensorflow-datasets\n","from typing import Dict, Text\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","import tensorflow_datasets as tfds\n","import tensorflow_recommenders as tfrs\n","# Ratings data.\n","ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n","# Features of all the available movies.\n","movies = tfds.load('movielens/100k-movies', split=\"train\")\n","\n","# Select the basic features.\n","ratings = ratings.map(lambda x: {\n","    \"movie_title\": x[\"movie_title\"],\n","    \"user_id\": x[\"user_id\"]\n","})\n","movies = movies.map(lambda x: x[\"movie_title\"])\n","user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n","user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n","\n","movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n","movie_titles_vocabulary.adapt(movies)\n","class MovieLensModel(tfrs.Model):\n","  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n","  # these are still plain Keras Models.\n","\n","  def __init__(\n","      self,\n","      user_model: tf.keras.Model,\n","      movie_model: tf.keras.Model,\n","      task: tfrs.tasks.Retrieval):\n","    super().__init__()\n","\n","    # Set up user and movie representations.\n","    self.user_model = user_model\n","    self.movie_model = movie_model\n","\n","    # Set up a retrieval task.\n","    self.task = task\n","\n","  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","    # Define how the loss is computed.\n","\n","    user_embeddings = self.user_model(features[\"user_id\"])\n","    movie_embeddings = self.movie_model(features[\"movie_title\"])\n","\n","    return self.task(user_embeddings, movie_embeddings)\n","   # Define user and movie models.\n","user_model = tf.keras.Sequential([\n","    user_ids_vocabulary,\n","    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n","])\n","movie_model = tf.keras.Sequential([\n","    movie_titles_vocabulary,\n","    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n","])\n","\n","# Define your objectives.\n","task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n","    movies.batch(128).map(movie_model)\n","  )\n",")\n","# Create a retrieval model.\n","model = MovieLensModel(user_model, movie_model, task)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n","\n","# Train for 3 epochs.\n","model.fit(ratings.batch(4096), epochs=3)\n","\n","# Use brute-force search to set up retrieval using the trained representations.\n","index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n","index.index_from_dataset(\n","    movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n","\n","# Get some recommendations.\n","_, titles = index(np.array([\"42\"]))\n","print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"]},{"cell_type":"markdown","source":[],"metadata":{"id":"de4ydjPAEyL4"}},{"cell_type":"markdown","source":["## RECOMMENDATION SYSTEM 2"],"metadata":{"id":"ISKLk0p4LDc1"}},{"cell_type":"markdown","source":["**Model 1: Collaborative Filtering using Matrix Factorization**"],"metadata":{"id":"DHkP9d9xE31e"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_recommenders as tfrs\n","\n","# Load data\n","ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n","movies = tfds.load('movielens/100k-movies', split=\"train\")\n","\n","# Select the basic features\n","ratings = ratings.map(lambda x: {\n","    \"movie_title\": x[\"movie_title\"],\n","    \"user_id\": x[\"user_id\"],\n","    \"user_rating\": x[\"user_rating\"]\n","})\n","movies = movies.map(lambda x: x[\"movie_title\"])\n","\n","# Create and adapt the vocabulary layers\n","user_ids_vocabulary = tf.keras.layers.StringLookup()\n","user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n","\n","movie_titles_vocabulary = tf.keras.layers.StringLookup()\n","movie_titles_vocabulary.adapt(movies)\n","\n","# Define the model\n","class MatrixFactorizationModel(tfrs.Model):\n","    def __init__(self, user_model, movie_model, rating_model, task):\n","        super().__init__()\n","        self.user_model = user_model\n","        self.movie_model = movie_model\n","        self.rating_model = rating_model\n","        self.task = task\n","\n","    def compute_loss(self, features, training=False):\n","        user_embeddings = self.user_model(features[\"user_id\"])\n","        movie_embeddings = self.movie_model(features[\"movie_title\"])\n","        ratings = features[\"user_rating\"]\n","\n","        predicted_ratings = self.rating_model(tf.concat([user_embeddings, movie_embeddings], axis=1))\n","        return self.task(ratings, predicted_ratings)\n","\n","# User and movie models\n","embedding_dimension = 32\n","user_model = tf.keras.Sequential([\n","    user_ids_vocabulary,\n","    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), embedding_dimension)\n","])\n","movie_model = tf.keras.Sequential([\n","    movie_titles_vocabulary,\n","    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), embedding_dimension)\n","])\n","\n","# Rating model\n","rating_model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=256, activation=\"relu\"),\n","    tf.keras.layers.Dense(units=64, activation=\"relu\"),\n","    tf.keras.layers.Dense(units=1)\n","])\n","\n","# Task and model\n","task = tfrs.tasks.Ranking(loss=tf.keras.losses.MeanSquaredError())\n","model = MatrixFactorizationModel(user_model, movie_model, rating_model, task)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n","\n","# Training\n","model.fit(ratings.batch(4096), epochs=3)\n","\n","# Evaluation\n","index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n","index.index_from_dataset(movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n","\n","# Recommendations\n","_, titles = index(np.array([\"42\"]))\n","print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iem_D1n54l_1","executionInfo":{"status":"ok","timestamp":1720102117734,"user_tz":-330,"elapsed":162088,"user":{"displayName":"Amrith eshwar","userId":"12227259083114899190"}},"outputId":"da316d79-a99b-458e-8905-afeafd5afeb4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n","WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","25/25 [==============================] - 4s 143ms/step - loss: 2.4793 - regularization_loss: 0.0000e+00 - total_loss: 2.4793\n","Epoch 2/3\n","25/25 [==============================] - 1s 56ms/step - loss: 1.1939 - regularization_loss: 0.0000e+00 - total_loss: 1.1939\n","Epoch 3/3\n","25/25 [==============================] - 1s 58ms/step - loss: 1.0737 - regularization_loss: 0.0000e+00 - total_loss: 1.0737\n","Top 3 recommendations for user 42: [b'Basquiat (1996)' b'Touch of Evil (1958)'\n"," b'Great Day in Harlem, A (1994)']\n"]}]},{"cell_type":"markdown","source":["# RECOMMENDATION SYSTEM 3"],"metadata":{"id":"ybcakXiCFGrf"}},{"cell_type":"markdown","source":["**Model 2: Hybrid Model (Collaborative Filtering + Content-Based Filtering)**"],"metadata":{"id":"i1LdE_dEFReX"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_recommenders as tfrs\n","\n","# Load data\n","ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n","movies = tfds.load('movielens/100k-movies', split=\"train\")\n","\n","# Select the basic features\n","ratings = ratings.map(lambda x: {\n","    \"movie_title\": x[\"movie_title\"],\n","    \"user_id\": x[\"user_id\"],\n","    \"user_rating\": x[\"user_rating\"]\n","})\n","movies = movies.map(lambda x: {\n","    \"movie_title\": x[\"movie_title\"]\n","})\n","\n","# Define the model\n","class HybridModel(tfrs.Model):\n","    def __init__(self, user_model, movie_model, rating_model, task):\n","        super().__init__()\n","        self.user_model = user_model\n","        self.movie_model = movie_model\n","        self.rating_model = rating_model\n","        self.task = task\n","\n","    def compute_loss(self, features, training=False):\n","        user_embeddings = self.user_model(features[\"user_id\"])\n","        movie_embeddings = self.movie_model(features[\"movie_title\"])\n","        ratings = features[\"user_rating\"]\n","\n","        predicted_ratings = self.rating_model(tf.concat([user_embeddings, movie_embeddings], axis=1))\n","        return self.task(ratings, predicted_ratings)\n","\n","# User and movie models\n","embedding_dimension = 32\n","\n","# Prepare StringLookup layers to adapt to the actual vocabulary\n","user_ids_vocabulary = tf.keras.layers.StringLookup()\n","movie_titles_vocabulary = tf.keras.layers.StringLookup()\n","\n","# Adapt the vocabularies to the dataset\n","user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n","movie_titles_vocabulary.adapt(ratings.map(lambda x: x[\"movie_title\"]))\n","\n","user_model = tf.keras.Sequential([\n","    user_ids_vocabulary,\n","    tf.keras.layers.Embedding(input_dim=user_ids_vocabulary.vocab_size(), output_dim=embedding_dimension)\n","])\n","\n","movie_model = tf.keras.Sequential([\n","    movie_titles_vocabulary,\n","    tf.keras.layers.Embedding(input_dim=movie_titles_vocabulary.vocab_size(), output_dim=embedding_dimension)\n","])\n","\n","# Rating model\n","rating_model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=256, activation=\"relu\"),\n","    tf.keras.layers.Dense(units=64, activation=\"relu\"),\n","    tf.keras.layers.Dense(units=1)\n","])\n","\n","# Task and model\n","task = tfrs.tasks.Ranking(loss=tf.keras.losses.MeanSquaredError())\n","model = HybridModel(user_model, movie_model, rating_model, task)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n","\n","# Training\n","model.fit(ratings.batch(4096), epochs=3)\n","\n","# Evaluation\n","index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n","index.index_from_dataset(\n","    movies.batch(100).map(lambda x: (x[\"movie_title\"], model.movie_model(x[\"movie_title\"])))\n",")\n","\n","# Recommendations\n","_, titles = index(np.array([\"42\"]))\n","print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKtFcM9uBZt4","executionInfo":{"status":"ok","timestamp":1720102471998,"user_tz":-330,"elapsed":354268,"user":{"displayName":"Amrith eshwar","userId":"12227259083114899190"}},"outputId":"7030a6b6-4ad0-4724-d6bf-d6d8892eecf5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n","WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","25/25 [==============================] - 4s 113ms/step - loss: 2.4940 - regularization_loss: 0.0000e+00 - total_loss: 2.4940\n","Epoch 2/3\n","25/25 [==============================] - 1s 54ms/step - loss: 1.2140 - regularization_loss: 0.0000e+00 - total_loss: 1.2140\n","Epoch 3/3\n","25/25 [==============================] - 1s 51ms/step - loss: 1.1106 - regularization_loss: 0.0000e+00 - total_loss: 1.1106\n","Top 3 recommendations for user 42: [b'Citizen Kane (1941)' b'Four Days in September (1997)'\n"," b'Bonheur, Le (1965)']\n"]}]}]}